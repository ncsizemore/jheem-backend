name: "[EXPERIMENTAL] Generate Native Data - Direct from Raw Simsets"

# ===========================================
# EXPERIMENTAL WORKFLOW - Full Pipeline Test
# ===========================================
# Tests the complete pipeline using raw simsets:
# 1. Download raw (1000-sim) simsets from GitHub Release
# 2. Run container batch mode to extract statistics
# 3. Aggregate into single state JSON
# 4. Extract summaries
# 5. (Optional) Upload to S3
#
# If this works, we can eliminate the 12-hour local trimming step!
# ===========================================

on:
  workflow_dispatch:
    inputs:
      states:
        description: 'States to generate'
        required: true
        default: 'single'
        type: choice
        options:
          - single    # Just AL for quick test
          - test      # 3 states (AL, CA, FL)
          - full      # All 30 states
      simulation_release:
        description: 'Raw simulation release tag'
        required: true
        default: 'ryan-white-state-v2.0.0'
        type: string
      container_image:
        description: 'Container image to use'
        required: true
        default: 'ghcr.io/ncsizemore/jheem-ryan-white-croi:latest'
        type: string
      dry_run:
        description: 'Skip S3 uploads'
        required: true
        default: true
        type: boolean
      max_parallel:
        description: 'Maximum parallel state jobs'
        required: true
        default: '3'
        type: string

env:
  # Full statistics
  STATISTICS: 'mean.and.interval,median.and.interval'

  # All facets including multi-dimensional
  FACETS: 'none,age,race,sex,risk,age+race,age+sex,age+risk,race+sex,race+risk,sex+risk,age+race+sex,age+race+risk,age+sex+risk,race+sex+risk,age+race+sex+risk'

  # All outcomes
  OUTCOMES: 'incidence,diagnosed.prevalence,suppression,testing,prep.uptake,awareness,rw.clients,adap.clients,non.adap.clients,oahs.clients,adap.proportion,oahs.suppression,adap.suppression,new'

  # All CROI scenarios (including conservative)
  SCENARIOS: 'cessation,interruption,cessation_conservative,interruption_conservative'

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      states: ${{ steps.set-states.outputs.states }}
    steps:
      - name: Set state list
        id: set-states
        run: |
          if [ "${{ github.event.inputs.states }}" == "single" ]; then
            echo 'states=["AL"]' >> $GITHUB_OUTPUT
            echo "Using SINGLE state (AL only)"
          elif [ "${{ github.event.inputs.states }}" == "test" ]; then
            echo 'states=["AL", "CA", "FL"]' >> $GITHUB_OUTPUT
            echo "Using TEST state set (3 states)"
          else
            echo 'states=["AL", "AR", "AZ", "CA", "CO", "FL", "GA", "IL", "IN", "KY", "LA", "MA", "MD", "MI", "MN", "MO", "MS", "NC", "NJ", "NV", "NY", "OH", "OK", "PA", "SC", "TN", "TX", "VA", "WA", "WI"]' >> $GITHUB_OUTPUT
            echo "Using FULL state set (30 states)"
          fi

  generate:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        state: ${{ fromJson(needs.prepare.outputs.states) }}
      max-parallel: ${{ fromJson(github.event.inputs.max_parallel) }}
      fail-fast: false
    steps:
      - name: Checkout jheem-portal (for aggregation scripts)
        uses: actions/checkout@v4
        with:
          repository: ncsizemore/jheem-portal
          path: portal

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install portal dependencies
        working-directory: portal
        run: npm ci

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Download RAW simulation data from GitHub Release
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üì• Downloading RAW simulation data for ${{ matrix.state }}"
          echo "‚ö†Ô∏è  These are UNTRIMMED simsets (~850MB each, 1000 simulations)"

          mkdir -p simulations/ryan-white/base
          mkdir -p simulations/ryan-white/prerun/${{ matrix.state }}

          # Download raw files
          gh release download ${{ github.event.inputs.simulation_release }} \
            --repo ncsizemore/jheem-simulations \
            --pattern "rw_final.ehe.state-1000_${{ matrix.state }}_*.Rdata" \
            --dir ./tmp-download

          echo "üì¶ Downloaded files:"
          ls -lh ./tmp-download/

          # Rename raw files to container's expected format
          mv "./tmp-download/rw_final.ehe.state-1000_${{ matrix.state }}_noint.Rdata" \
            "simulations/ryan-white/base/${{ matrix.state }}_base.Rdata"

          mv "./tmp-download/rw_final.ehe.state-1000_${{ matrix.state }}_rw.end.26.Rdata" \
            "simulations/ryan-white/prerun/${{ matrix.state }}/cessation.Rdata"

          mv "./tmp-download/rw_final.ehe.state-1000_${{ matrix.state }}_rw.p.intr.26.Rdata" \
            "simulations/ryan-white/prerun/${{ matrix.state }}/interruption.Rdata"

          mv "./tmp-download/rw_final.ehe.state-1000_${{ matrix.state }}_rw.end.cons.26.Rdata" \
            "simulations/ryan-white/prerun/${{ matrix.state }}/cessation_conservative.Rdata"

          mv "./tmp-download/rw_final.ehe.state-1000_${{ matrix.state }}_rw.p.intr.cons.26.Rdata" \
            "simulations/ryan-white/prerun/${{ matrix.state }}/interruption_conservative.Rdata"

          echo "‚úÖ Renamed to container format:"
          ls -la simulations/ryan-white/base/
          ls -la simulations/ryan-white/prerun/${{ matrix.state }}/

          echo ""
          echo "üìä Total simulation data size:"
          du -sh simulations/

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate native data
        run: |
          echo "üèõÔ∏è Generating native data for ${{ matrix.state }} (DIRECT from raw simsets)"

          mkdir -p output/${{ matrix.state }}

          echo "Memory before container:"
          free -h

          set +e
          docker run --rm \
            -v $(pwd)/simulations:/app/simulations:ro \
            -v $(pwd)/output/${{ matrix.state }}:/output \
            ${{ github.event.inputs.container_image }} \
            batch \
            --city ${{ matrix.state }} \
            --scenarios ${{ env.SCENARIOS }} \
            --outcomes ${{ env.OUTCOMES }} \
            --statistics ${{ env.STATISTICS }} \
            --facets "${{ env.FACETS }}" \
            --output-dir /output \
            --output-mode data
          exit_code=$?
          set -e

          echo ""
          echo "Memory after container:"
          free -h

          if [ "$exit_code" -eq 137 ]; then
            echo "‚ùå OOM KILLED (exit code 137)"
            exit 1
          fi

          file_count=$(find output/${{ matrix.state }} -name "*.json" 2>/dev/null | wc -l)
          echo "üìä Files generated: $file_count"

          if [ "$file_count" -eq 0 ]; then
            echo "‚ùå No files generated"
            exit 1
          fi

          echo "‚úÖ Generated $file_count files"

      - name: Aggregate state data
        working-directory: portal
        run: |
          echo "üìä Aggregating data for ${{ matrix.state }}..."

          mkdir -p public/data

          state_dir="../output/${{ matrix.state }}/${{ matrix.state }}"
          if [ ! -d "$state_dir" ]; then
            state_dir="../output/${{ matrix.state }}"
          fi

          echo "Using state directory: $state_dir"

          npx tsx scripts/aggregate-city-data.ts "$state_dir" "public/data/${{ matrix.state }}.json"

          if [ -f "public/data/${{ matrix.state }}.json" ]; then
            size=$(ls -lh "public/data/${{ matrix.state }}.json" | awk '{print $5}')
            echo "‚úÖ Created ${{ matrix.state }}.json ($size)"
          else
            echo "‚ùå Failed to create ${{ matrix.state }}.json"
            exit 1
          fi

      - name: Extract state summary
        working-directory: portal
        run: |
          echo "üìã Extracting summary for ${{ matrix.state }}..."

          npx tsx scripts/generate-state-summaries.ts --single ${{ matrix.state }} "public/data/${{ matrix.state }}.json"

          mv "${{ matrix.state }}-summary.json" "public/data/${{ matrix.state }}-summary.json"

          echo "‚úÖ Summary extracted:"
          cat "public/data/${{ matrix.state }}-summary.json"

      - name: Upload summary artifact
        uses: actions/upload-artifact@v4
        with:
          name: summary-${{ matrix.state }}
          path: portal/public/data/${{ matrix.state }}-summary.json
          retention-days: 1

      - name: Upload to S3
        if: ${{ github.event.inputs.dry_run != 'true' }}
        working-directory: portal
        run: |
          echo "‚òÅÔ∏è Uploading ${{ matrix.state }}.json to S3..."

          gzip -c "public/data/${{ matrix.state }}.json" > "public/data/${{ matrix.state }}.json.gz"

          aws s3 cp "public/data/${{ matrix.state }}.json.gz" \
            "s3://jheem-data-production/portal/ryan-white-state-croi/${{ matrix.state }}.json" \
            --content-type "application/json" \
            --content-encoding "gzip"

          echo "‚úÖ Uploaded to S3"

      - name: Skip S3 upload (dry run)
        if: ${{ github.event.inputs.dry_run == 'true' }}
        working-directory: portal
        run: |
          echo "üî∏ DRY RUN - Skipping S3 upload"
          echo "üìä Would upload: public/data/${{ matrix.state }}.json"
          ls -lh "public/data/${{ matrix.state }}.json"

  finalize:
    needs: [prepare, generate]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout jheem-portal
        uses: actions/checkout@v4
        with:
          repository: ncsizemore/jheem-portal
          path: portal

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        working-directory: portal
        run: npm ci

      - name: Configure AWS credentials
        if: ${{ github.event.inputs.dry_run != 'true' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Download summary artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: summary-*
          path: summaries
          merge-multiple: true

      - name: List downloaded summaries
        run: |
          echo "üì• Downloaded summary artifacts:"
          ls -lh summaries/
          echo ""
          echo "Contents:"
          for f in summaries/*.json; do
            echo "=== $f ==="
            cat "$f"
            echo ""
          done

      - name: Combine state summaries
        working-directory: portal
        run: |
          echo "üìã Combining state summaries..."

          summary_files=$(find ../summaries -name "*-summary.json" | sort | tr '\n' ' ')
          echo "Found summaries: $summary_files"

          npx tsx scripts/generate-state-summaries.ts --combine $summary_files

          if [ -f "public/data/state-summaries.json" ]; then
            echo "‚úÖ Combined summaries:"
            cat public/data/state-summaries.json
          else
            echo "‚ùå Summaries file not created"
            exit 1
          fi

      - name: Upload state summaries to S3
        if: ${{ github.event.inputs.dry_run != 'true' }}
        working-directory: portal
        run: |
          echo "‚òÅÔ∏è Uploading state-summaries.json to S3..."

          gzip -c public/data/state-summaries.json > public/data/state-summaries.json.gz
          aws s3 cp public/data/state-summaries.json.gz \
            "s3://jheem-data-production/portal/ryan-white-state-croi/state-summaries.json" \
            --content-type "application/json" \
            --content-encoding "gzip"

          echo ""
          echo "=========================================="
          echo "üìä DIRECT PIPELINE TEST COMPLETE"
          echo "=========================================="
          echo ""
          echo "üåê Files available at:"
          echo "   https://d320iym4dtm9lj.cloudfront.net/ryan-white-state-croi/{STATE}.json"

      - name: Summary (dry run)
        if: ${{ github.event.inputs.dry_run == 'true' }}
        run: |
          echo ""
          echo "=========================================="
          echo "üìä DIRECT PIPELINE TEST COMPLETE (DRY RUN)"
          echo "=========================================="
          echo ""
          echo "‚úÖ Full pipeline executed successfully!"
          echo "‚úÖ Raw simsets ‚Üí JSON extraction ‚Üí Aggregation ‚Üí Summary"
          echo ""
          echo "This proves the direct approach works end-to-end."
          echo "No 12-hour local trimming step needed!"
