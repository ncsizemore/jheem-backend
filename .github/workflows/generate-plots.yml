name: Generate JHEEM Plots

on:
  workflow_dispatch:
    inputs:
      config_type:
        description: 'Configuration type'
        required: true
        default: 'test'
        type: choice
        options:
        - minimal
        - test
        - medium
        - full
      max_parallel:
        description: 'Maximum parallel jobs'
        required: true
        default: '2'
        type: string
      
jobs:
  # First job: Generate configuration and prepare simulation data
  prepare:
    runs-on: ubuntu-latest
    outputs:
      cities: ${{ steps.config.outputs.cities }}
      total_plots: ${{ steps.config.outputs.total_plots }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Python dependencies
        run: |
          pip install pyyaml argparse
          
      - name: Generate orchestration configuration
        id: config
        run: |
          # Run the script from repo root so paths work correctly
          python scripts/generate_orchestration_config.py --type ${{ github.event.inputs.config_type }}
          
          # Extract cities list for matrix strategy  
          python -c "
          import yaml
          with open('orchestration_configs/master_config_${{ github.event.inputs.config_type }}.yaml', 'r') as f:
              config = yaml.safe_load(f)
          cities = [job['city'] for job in config['jobs']]
          total_plots = config['total_expected_plots']
          print(f'cities={cities}'.replace(\"'\", '\"'))
          print(f'total_plots={total_plots}')
          " >> $GITHUB_OUTPUT
          
      - name: Upload configuration artifacts
        uses: actions/upload-artifact@v4
        with:
          name: orchestration-config
          path: orchestration_configs/

  # Second job: Generate plots per city (matrix strategy)
  generate-plots:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        city: ${{ fromJson(needs.prepare.outputs.cities) }}
      max-parallel: ${{ fromJson(github.event.inputs.max_parallel) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
          
      - name: Verify AWS connection
        run: |
          echo "🔐 Testing AWS connection..."
          aws sts get-caller-identity
          echo "✅ AWS connection successful"
          
      - name: Download configuration
        uses: actions/download-artifact@v4
        with:
          name: orchestration-config
          path: orchestration_configs/
          
      - name: Download simulation data for city
        run: |
          echo "📥 Downloading simulation data for city: ${{ matrix.city }}"
          
          # Create directories for simulation data
          mkdir -p simulations/ryan-white/base
          mkdir -p simulations/ryan-white/prerun/${{ matrix.city }}
          
          # Download base simulation data for this city
          echo "📥 Downloading base simulation: ${{ matrix.city }}_base.Rdata"
          aws s3 cp s3://jheem-data-production/simulations/ryan-white/base/${{ matrix.city }}_base.Rdata \
            simulations/ryan-white/base/${{ matrix.city }}_base.Rdata
          
          # Download prerun simulation data for all scenarios in the job config
          echo "📥 Downloading prerun simulations for ${{ matrix.city }}"
          aws s3 sync s3://jheem-data-production/simulations/ryan-white/prerun/${{ matrix.city }}/ \
            simulations/ryan-white/prerun/${{ matrix.city }}/
          
          # Verify downloads
          echo "✅ Base simulation downloaded:"
          ls -la simulations/ryan-white/base/${{ matrix.city }}_base.Rdata
          echo "✅ Prerun simulations downloaded:"
          ls -la simulations/ryan-white/prerun/${{ matrix.city }}/

      - name: Generate real plots using container
        run: |
          echo "🏙️ Generating real plots for city: ${{ matrix.city }}"
          
          # Create output directory
          mkdir -p plots
          
          # Find the job config file for this city
          JOB_CONFIG=$(find orchestration_configs -name "job_${{ github.event.inputs.config_type }}_*_${{ matrix.city }}.yaml" | head -1)
          echo "📋 Using job config: $JOB_CONFIG"
          
          # Log in to ECR
          echo "🔐 Logging in to ECR..."
          aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 849611540600.dkr.ecr.us-east-1.amazonaws.com
          
          # Generate real plots using container
          echo "🐳 Running container plot generation..."
          
          # Capture full container output and exit code
          set +e  # Don't exit immediately on error, so we can capture output
          docker_output=$(docker run --rm \
            -v $(pwd)/simulations:/app/simulations:ro \
            -v $(pwd)/plots:/app/plots \
            -v $(pwd)/orchestration_configs:/app/configs:ro \
            849611540600.dkr.ecr.us-east-1.amazonaws.com/jheem-ryan-white-model:latest batch \
            --config /app/configs/$(basename "$JOB_CONFIG") \
            ${{ github.event.inputs.config_type == 'minimal' && '--include-html' || '' }} \
            --s3-bucket jheem-test-tiny-bucket 2>&1)
          docker_exit_code=$?
          set -e  # Re-enable exit on error
          
          # Always show container output for debugging
          echo "🔍 Full container output:"
          echo "$docker_output"
          echo "🔍 Container exit code: $docker_exit_code"
          
          # Show generated files regardless of exit code
          echo "📊 Real plots generated via container:"
          json_count=$(find plots -name "*.json" | wc -l)
          html_count=$(find plots -name "*.html" | wc -l)
          echo "   - JSON files: $json_count"
          echo "   - HTML files: $html_count"
          
          # If container failed, fail the workflow (for debugging)
          if [ $docker_exit_code -ne 0 ]; then
            echo "❌ Container failed with exit code: $docker_exit_code"
            echo "📋 Failing workflow to avoid costs during debugging"
            exit $docker_exit_code
          else
            echo "✅ Container completed successfully"
          fi
          
      - name: Upload plots to S3
        run: |
          echo "📤 Uploading plots to S3..."
          
          # Upload JSON and HTML files to S3
          for plot_file in $(find plots -name "*.json" -o -name "*.html"); do
            if [[ -f "$plot_file" ]]; then
              # Preserve directory structure in S3 key, removing city prefix to avoid duplication
              relative_path=${plot_file#plots/}
              # Remove city directory from path since it's already in the S3 prefix
              clean_path=${relative_path#*/}
              s3_key="github_actions_integration/${{ matrix.city }}/${clean_path}"
              
              echo "📤 Uploading: $plot_file → s3://jheem-test-tiny-bucket/$s3_key"
              aws s3 cp "$plot_file" "s3://jheem-test-tiny-bucket/$s3_key" \
                --metadata "city=${{ matrix.city }},source=github_actions_container,config_type=${{ github.event.inputs.config_type }},timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
                
              if [[ $? -eq 0 ]]; then
                echo "✅ Successfully uploaded: $s3_key"
              else
                echo "❌ Failed to upload: $s3_key"
                exit 1
              fi
            fi
          done
          
      - name: Register plots in DynamoDB
        run: |
          echo "📋 Registering plot metadata in DynamoDB..."
          
          # Register each JSON plot file in DynamoDB (only JSON files, not HTML or metadata)
          for plot_file in $(find plots -name "*.json" ! -name "*_metadata.json"); do
            if [[ -f "$plot_file" ]]; then
              # Extract plot information from filename and path
              relative_path=${plot_file#plots/}
              filename=$(basename "$plot_file")
              # Remove city directory from path to avoid duplication
              clean_path=${relative_path#*/}
              s3_key="github_actions_integration/${{ matrix.city }}/${clean_path}"
              file_size=$(stat -c%s "$plot_file" 2>/dev/null || stat -f%z "$plot_file")
              
              # Parse plot details from container-generated filename
              # Expected format: outcome_statistic_facet.json or outcome_statistic_facet_facetvalue.json
              base_name=$(echo $filename | sed 's/.json$//')
              
              # Extract metadata from the JSON file if it exists
              if command -v jq &> /dev/null && jq -e '.metadata' "$plot_file" > /dev/null 2>&1; then
                scenario=$(jq -r '.metadata.scenario // "unknown"' "$plot_file")
                outcome=$(jq -r '.metadata.outcome // "unknown"' "$plot_file") 
                statistic=$(jq -r '.metadata.statistic // "unknown"' "$plot_file")
                facet=$(jq -r '.metadata.facet // "unknown"' "$plot_file")
              else
                # Fallback parsing from filename
                scenario="cessation"  # Default for minimal test
                outcome=$(echo $base_name | cut -d'_' -f1)
                statistic="mean.and.interval"
                facet="none"
              fi
              
              # Create composite keys for Lambda compatibility
              city_scenario="${{ matrix.city }}#${scenario}"
              outcome_stat_facet="${outcome}#${statistic}#${facet}"
              plot_id="container_${{ matrix.city }}_${base_name}"
              
              echo "📋 Registering: $plot_id (city_scenario: $city_scenario, outcome_stat_facet: $outcome_stat_facet)"
              
              # Create DynamoDB item with Lambda-compatible schema
              aws dynamodb put-item \
                --table-name jheem-test-tiny \
                --item "{
                  \"city_scenario\": {\"S\": \"$city_scenario\"},
                  \"outcome_stat_facet\": {\"S\": \"$outcome_stat_facet\"},
                  \"outcome\": {\"S\": \"$outcome\"},
                  \"statistic_type\": {\"S\": \"$statistic\"},
                  \"facet_choice\": {\"S\": \"$facet\"},
                  \"s3_key\": {\"S\": \"$s3_key\"},
                  \"file_size\": {\"N\": \"$file_size\"},
                  \"source\": {\"S\": \"github_actions_container\"},
                  \"config_type\": {\"S\": \"${{ github.event.inputs.config_type }}\"},
                  \"created_at\": {\"S\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}
                }"
                
              if [[ $? -eq 0 ]]; then
                echo "✅ Successfully registered: $plot_id"
              else
                echo "❌ Failed to register: $plot_id"
                exit 1
              fi
            fi
          done
          
      - name: Verify uploads
        run: |
          echo "🔍 Verifying uploads..."
          
          # List uploaded files in S3
          echo "📁 S3 files for ${{ matrix.city }}:"
          aws s3 ls "s3://jheem-test-tiny-bucket/github_actions_integration/${{ matrix.city }}/" --recursive || echo "No files found"
          
          # Query DynamoDB for registered plots using new composite key schema
          echo "📊 DynamoDB records for ${{ matrix.city }}:"
          aws dynamodb scan \
            --table-name jheem-test-tiny \
            --filter-expression "begins_with(city_scenario, :city) AND contains(#source, :container_source)" \
            --expression-attribute-names '{"#source": "source"}' \
            --expression-attribute-values '{":city":{"S":"${{ matrix.city }}#"}, ":container_source":{"S":"container"}}' \
            --query "Items[*].[city_scenario.S, outcome_stat_facet.S, outcome.S, s3_key.S]" \
            --output table || echo "No records found"
            
      - name: Report completion
        run: |
          # Count actual generated files
          json_count=$(find plots -name "*.json" | wc -l)
          html_count=$(find plots -name "*.html" | wc -l)
          
          # Count registered DynamoDB records
          registered_count=$(aws dynamodb scan \
            --table-name jheem-test-tiny \
            --filter-expression "begins_with(city_scenario, :city) AND contains(#source, :container_source)" \
            --expression-attribute-names '{"#source": "source"}' \
            --expression-attribute-values '{":city":{"S":"${{ matrix.city }}#"}, ":container_source":{"S":"container"}}' \
            --select COUNT \
            --query "Count" || echo "0")
          
          echo "📊 Final results for ${{ matrix.city }}:"
          echo "   - JSON files: $json_count"
          echo "   - HTML files: $html_count" 
          echo "📋 Registered $json_count metadata records in DynamoDB"
          echo "💾 Files stored under: github_actions_integration/${{ matrix.city }}/"
          echo "🎯 Config type: ${{ github.event.inputs.config_type }}"
          
  # Third job: Summarize results
  summarize:
    needs: [prepare, generate-plots]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
          
      - name: Generate summary
        run: |
          echo "🎯 JHEEM Plot Generation Summary"
          echo "================================"
          echo "Configuration: ${{ github.event.inputs.config_type }}"
          echo "Total expected plots: ${{ needs.prepare.outputs.total_plots }}"
          echo "Parallel jobs: ${{ github.event.inputs.max_parallel }}"
          echo ""
          echo "📊 AWS Integration Results:"
          
          # Count total files uploaded
          total_files=$(aws s3 ls s3://jheem-test-tiny-bucket/github_actions_test/ --recursive | wc -l || echo "0")
          echo "   - S3 files uploaded: $total_files"
          
          # Count total DynamoDB records
          total_records=$(aws dynamodb scan \
            --table-name jheem-test-tiny \
            --filter-expression "contains(plot_id, :prefix)" \
            --expression-attribute-values '{":prefix":{"S":"gh_"}}' \
            --select COUNT \
            --query "Count" --output text || echo "0")
          echo "   - DynamoDB records: $total_records"
          
          echo ""
          echo "✅ AWS integration test complete!"
          echo "🔗 View results in AWS Console:"
          echo "   - S3: https://console.aws.amazon.com/s3/buckets/jheem-test-tiny-bucket"
          echo "   - DynamoDB: https://console.aws.amazon.com/dynamodb/"
